import { Router } from "express";
import { authenticateUser } from "../auth/rbac-middleware.js";
import { db } from "../../db.js";
import { randomUUID } from "crypto";
import { exec } from "child_process";
import { promisify } from "util";
import fs from "fs/promises";
import path from "path";

const execAsync = promisify(exec);
const router = Router();

/**
 * Stage promotion tracking
 */
interface PromotionRecord {
  id: string;
  fromStage: string;
  toStage: string;
  promotedBy: string;
  promotedAt: string;
  dataSnapshot: any;
  sqlScript?: string;
  status: "pending" | "completed" | "failed";
  executionLog?: string;
}

const promotionHistory: PromotionRecord[] = [];

/**
 * GET /api/stages/current
 * Get current deployment stage and database info
 * üîí Superadmin only
 */
router.get("/current", authenticateUser, async (req, res) => {
  try {
    if (req.user?.role !== "superadmin") {
      return res.status(403).json({ error: "Superadmin access required" });
    }

    const currentStage = process.env.NODE_ENV || "development";
    const dbType = process.env.DB_TYPE || "sqlite";
    const databaseUrl = process.env.DATABASE_URL;

    // Get database statistics
    let dbStats: any = {};
    
    if (dbType === "postgres") {
      try {
        // PostgreSQL stats
        const result = await db.execute(`
          SELECT 
            pg_size_pretty(pg_database_size(current_database())) as db_size,
            (SELECT count(*) FROM information_schema.tables WHERE table_schema = 'public') as table_count
        `);
        dbStats = result.rows?.[0] || {};
      } catch (e) {
        console.warn("Failed to get PostgreSQL stats:", e);
      }
    }

    res.json({
      currentStage,
      dbType,
      databaseUrl: databaseUrl ? maskConnectionString(databaseUrl) : null,
      dbStats,
      promotionHistory: promotionHistory.slice(-10), // Last 10 promotions
    });
  } catch (error: any) {
    res.status(500).json({ error: error.message });
  }
});

/**
 * POST /api/stages/generate-migration
 * Generate SQL migration script for promotion
 * üîí Superadmin only
 */
router.post("/generate-migration", authenticateUser, async (req, res) => {
  try {
    if (req.user?.role !== "superadmin") {
      return res.status(403).json({ error: "Superadmin access required" });
    }

    const { fromStage, toStage, includeData } = req.body;

    if (!fromStage || !toStage) {
      return res.status(400).json({ error: "fromStage and toStage are required" });
    }

    // Validate stage progression
    const validStages = ["dev", "test", "staging", "prod"];
    const fromIndex = validStages.indexOf(fromStage);
    const toIndex = validStages.indexOf(toStage);

    if (fromIndex === -1 || toIndex === -1) {
      return res.status(400).json({ error: "Invalid stage names" });
    }

    if (toIndex <= fromIndex) {
      return res.status(400).json({ error: "Can only promote to higher stages" });
    }

    console.log(`üöÄ Generating migration: ${fromStage} ‚Üí ${toStage}`);

    // Generate schema migration using drizzle-kit
    const timestamp = new Date().toISOString().replace(/[:.]/g, "-");
    const migrationDir = path.join(process.cwd(), "migrations", `${fromStage}-to-${toStage}-${timestamp}`);
    
    await fs.mkdir(migrationDir, { recursive: true });

    // Generate Drizzle schema snapshot
    let schemaSQL = "";
    let dataSQL = "";

    try {
      // Use drizzle-kit to generate schema
      const dbType = process.env.DB_TYPE || "postgres";
      const schemaPath = dbType === "postgres" ? "schema.pg.ts" : "schema.ts";
      
      // Generate schema export
      const { stdout } = await execAsync(`npx drizzle-kit generate --schema=server/${schemaPath} --out=${migrationDir}`);
      console.log("Schema generated:", stdout);

      // Read generated SQL
      const files = await fs.readdir(migrationDir);
      const sqlFile = files.find(f => f.endsWith('.sql'));
      
      if (sqlFile) {
        schemaSQL = await fs.readFile(path.join(migrationDir, sqlFile), 'utf-8');
      }
    } catch (error: any) {
      console.error("Schema generation failed:", error);
      schemaSQL = `-- Schema generation failed: ${error.message}\n-- Manual schema review required`;
    }

    // Generate data migration if requested
    if (includeData) {
      dataSQL = await generateDataMigration(fromStage, toStage);
    }

    // Combine into single migration script
    const fullMigration = `
-- ============================================================================
-- ContinuityBridge Stage Promotion
-- From: ${fromStage.toUpperCase()}
-- To: ${toStage.toUpperCase()}
-- Generated: ${new Date().toISOString()}
-- Generated by: ${req.user?.email}
-- ============================================================================

-- IMPORTANT: Review this script before executing in production!
-- Run in a transaction to allow rollback if issues occur.

BEGIN;

-- ============================================================================
-- SCHEMA MIGRATION
-- ============================================================================

${schemaSQL}

${includeData ? `
-- ============================================================================
-- DATA MIGRATION
-- ============================================================================

${dataSQL}
` : '-- Data migration skipped (schema only)'}

-- ============================================================================
-- VERIFICATION QUERIES
-- ============================================================================

-- Check table counts
SELECT 
  schemaname,
  tablename,
  pg_size_pretty(pg_total_relation_size(schemaname||'.'||tablename)) AS size
FROM pg_tables 
WHERE schemaname = 'public'
ORDER BY pg_total_relation_size(schemaname||'.'||tablename) DESC;

-- Verify critical tables exist
SELECT EXISTS (SELECT FROM information_schema.tables WHERE table_name = 'users') as users_exists,
       EXISTS (SELECT FROM information_schema.tables WHERE table_name = 'waf_config') as waf_config_exists,
       EXISTS (SELECT FROM information_schema.tables WHERE table_name = 'magic_links') as magic_links_exists;

COMMIT;
-- If everything looks good, COMMIT. Otherwise, ROLLBACK;
`.trim();

    // Save migration script
    const scriptPath = path.join(migrationDir, `migrate-${fromStage}-to-${toStage}.sql`);
    await fs.writeFile(scriptPath, fullMigration);

    // Create promotion record
    const promotionRecord: PromotionRecord = {
      id: randomUUID(),
      fromStage,
      toStage,
      promotedBy: req.user?.email || "unknown",
      promotedAt: new Date().toISOString(),
      dataSnapshot: includeData,
      sqlScript: scriptPath,
      status: "pending",
    };

    promotionHistory.push(promotionRecord);

    res.json({
      success: true,
      migration: {
        id: promotionRecord.id,
        fromStage,
        toStage,
        scriptPath,
        script: fullMigration,
        size: fullMigration.length,
      },
      message: `Migration script generated. Review and execute manually on ${toStage} database.`,
    });
  } catch (error: any) {
    res.status(500).json({ error: error.message });
  }
});

/**
 * POST /api/stages/execute-migration
 * Execute migration on target database
 * üîí Superadmin only - USE WITH EXTREME CAUTION
 */
router.post("/execute-migration", authenticateUser, async (req, res) => {
  try {
    if (req.user?.role !== "superadmin") {
      return res.status(403).json({ error: "Superadmin access required" });
    }

    const { promotionId, databaseUrl, dryRun } = req.body;

    if (!promotionId) {
      return res.status(400).json({ error: "promotionId is required" });
    }

    const promotion = promotionHistory.find(p => p.id === promotionId);
    if (!promotion) {
      return res.status(404).json({ error: "Promotion not found" });
    }

    if (!promotion.sqlScript) {
      return res.status(400).json({ error: "No SQL script found for this promotion" });
    }

    // Read SQL script
    const sqlScript = await fs.readFile(promotion.sqlScript, 'utf-8');

    let executionLog = "";

    if (dryRun) {
      executionLog = "DRY RUN - Script validation only\n";
      executionLog += `Script size: ${sqlScript.length} bytes\n`;
      executionLog += `Lines: ${sqlScript.split('\n').length}\n`;
      executionLog += "\nScript validated. No changes made.\n";

      promotion.status = "pending";
      promotion.executionLog = executionLog;
    } else {
      // REAL EXECUTION - BE VERY CAREFUL
      executionLog = "EXECUTING MIGRATION\n";
      executionLog += `Promotion: ${promotion.fromStage} ‚Üí ${promotion.toStage}\n`;
      executionLog += `Started: ${new Date().toISOString()}\n\n`;

      try {
        // Execute on target database
        const targetUrl = databaseUrl || process.env.DATABASE_URL;
        
        if (!targetUrl) {
          throw new Error("No database URL provided");
        }

        executionLog += `Target database: ${maskConnectionString(targetUrl)}\n`;
        executionLog += "Executing SQL...\n\n";

        // Save script to temp file and execute via psql
        const tempScript = path.join(process.cwd(), 'temp-migration.sql');
        await fs.writeFile(tempScript, sqlScript);

        try {
          const { stdout, stderr } = await execAsync(
            `psql "${targetUrl}" -f ${tempScript}`,
            { maxBuffer: 1024 * 1024 * 10 } // 10MB buffer
          );

          executionLog += "STDOUT:\n" + stdout + "\n";
          if (stderr) {
            executionLog += "STDERR:\n" + stderr + "\n";
          }

          // Clean up temp file
          await fs.unlink(tempScript);

          promotion.status = "completed";
          executionLog += "\n‚úÖ Migration completed successfully\n";
        } catch (execError: any) {
          // Clean up temp file even on error
          try {
            await fs.unlink(tempScript);
          } catch {}

          promotion.status = "failed";
          executionLog += "\n‚ùå Migration failed\n";
          executionLog += execError.message + "\n";
          if (execError.stdout) executionLog += "STDOUT: " + execError.stdout + "\n";
          if (execError.stderr) executionLog += "STDERR: " + execError.stderr + "\n";
        }

      } catch (error: any) {
        promotion.status = "failed";
        executionLog += "\n‚ùå Execution failed: " + error.message + "\n";
      }

      promotion.executionLog = executionLog;
      executionLog += `Completed: ${new Date().toISOString()}\n`;
    }

    res.json({
      success: promotion.status === "completed",
      promotion,
      executionLog,
    });
  } catch (error: any) {
    res.status(500).json({ error: error.message });
  }
});

/**
 * GET /api/stages/promotions
 * Get promotion history
 * üîí Superadmin only
 */
router.get("/promotions", authenticateUser, async (req, res) => {
  try {
    if (req.user?.role !== "superadmin") {
      return res.status(403).json({ error: "Superadmin access required" });
    }

    res.json({
      promotions: promotionHistory.sort((a, b) => 
        new Date(b.promotedAt).getTime() - new Date(a.promotedAt).getTime()
      ),
      total: promotionHistory.length,
    });
  } catch (error: any) {
    res.status(500).json({ error: error.message });
  }
});

/**
 * Helper: Generate data migration SQL
 */
async function generateDataMigration(fromStage: string, toStage: string): Promise<string> {
  let dataSQL = `-- Data Migration: ${fromStage} ‚Üí ${toStage}\n\n`;

  try {
    // Import tables dynamically
    const { users, wafConfig } = await import("../../db.js");

    // Export users with stage-specific API keys
    const allUsers = await (db.select().from(users) as any);
    
    if (allUsers && allUsers.length > 0) {
      dataSQL += `-- Insert users (${allUsers.length} records)\n`;
      
      for (const user of allUsers) {
        // Update API key for target stage
        const newApiKey = user.apiKey?.replace(
          /cb_(dev|test|staging|prod)_/,
          `cb_${toStage}_`
        );

        const escapedEmail = user.email.replace(/'/g, "''");
        const escapedOrgName = (user.organizationName || '').replace(/'/g, "''");
        
        dataSQL += `
INSERT INTO users (id, email, role, api_key, organization_id, organization_name, enabled, created_at)
VALUES (
  '${user.id}',
  '${escapedEmail}',
  '${user.role}',
  '${newApiKey}',
  ${user.organizationId ? `'${user.organizationId}'` : 'NULL'},
  ${user.organizationName ? `'${escapedOrgName}'` : 'NULL'},
  ${user.enabled},
  '${user.createdAt}'
)
ON CONFLICT (id) DO UPDATE SET
  email = EXCLUDED.email,
  api_key = EXCLUDED.api_key,
  updated_at = NOW();
`;
      }
    }

    // Export WAF configuration
    const wafConfigs = await (db.select().from(wafConfig) as any);
    
    if (wafConfigs && wafConfigs.length > 0) {
      dataSQL += `\n-- Insert WAF configurations (${wafConfigs.length} records)\n`;
      
      for (const config of wafConfigs) {
        const whitelist = JSON.stringify(config.whitelist || []).replace(/'/g, "''");
        
        dataSQL += `
INSERT INTO waf_config (
  id, organization_id, enabled, block_bots, block_suspicious,
  rate_limit_enabled, rate_limit_window_ms, rate_limit_max_requests, rate_limit_block_duration_ms,
  whitelist, created_at
)
VALUES (
  '${config.id}',
  ${config.organizationId ? `'${config.organizationId}'` : 'NULL'},
  ${config.enabled},
  ${config.blockBots},
  ${config.blockSuspicious},
  ${config.rateLimitEnabled},
  ${config.rateLimitWindowMs},
  ${config.rateLimitMaxRequests},
  ${config.rateLimitBlockDurationMs},
  '${whitelist}'::jsonb,
  '${config.createdAt}'
)
ON CONFLICT (id) DO UPDATE SET
  enabled = EXCLUDED.enabled,
  block_bots = EXCLUDED.block_bots,
  updated_at = NOW();
`;
      }
    }

  } catch (error: any) {
    dataSQL += `\n-- ‚ö†Ô∏è  Data export failed: ${error.message}\n`;
    dataSQL += `-- Please export data manually\n`;
  }

  return dataSQL;
}

/**
 * Helper: Mask connection string for security
 */
function maskConnectionString(url: string): string {
  try {
    const urlObj = new URL(url);
    if (urlObj.password) {
      urlObj.password = '****';
    }
    return urlObj.toString();
  } catch {
    return url.replace(/:[^:@]+@/, ':****@');
  }
}

export default router;
